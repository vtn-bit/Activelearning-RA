import os
import google.generativeai as genai
import pandas as pd
import streamlit as st
import time
from docx import Document
import datetime

# üîß ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ò‡∏µ‡∏°‡∏™‡∏µ‡∏ü‡πâ‡∏≤‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß‡∏Ç‡∏≤‡∏ß
def setup_custom_theme():
    st.markdown("""
    <style>
    /* ‡∏ò‡∏µ‡∏°‡∏™‡∏µ‡∏ü‡πâ‡∏≤‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß‡∏Ç‡∏≤‡∏ß */
    :root {
        --primary-color: #1E88E5;    /* ‡∏ü‡πâ‡∏≤‡πÄ‡∏Ç‡πâ‡∏° */
        --secondary-color: #4DB6AC;  /* ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß‡∏ü‡πâ‡∏≤ */
        --accent-color: #26C6DA;     /* ‡∏ü‡πâ‡∏≤‡∏≠‡πà‡∏≠‡∏ô */
        --background-color: #F5F7FA; /* ‡πÄ‡∏ó‡∏≤‡∏≠‡πà‡∏≠‡∏ô */
        --text-color: #263238;       /* ‡πÄ‡∏ó‡∏≤‡πÄ‡∏Ç‡πâ‡∏° */
        --card-color: #FFFFFF;       /* ‡∏Ç‡∏≤‡∏ß */
    }
    
    .main-header {
        background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));
        padding: 2rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 1rem;
    }
    
    .chat-user {
        background-color: var(--primary-color) !important;
        color: white !important;
        border-radius: 15px 15px 0px 15px !important;
        padding: 12px 16px !important; 
        margin: 4px 0 !important;
        line-height: 1.5 !important;
    }
    
    .chat-assistant {
         background-color: var(--secondary-color) !important;
        color: white !important;
        border-radius: 15px 15px 15px 0px !important;
        padding: 12px 16px !important;  
        margin: 4px 0 !important;
        line-height: 1.5 !important;
    }
    
    .sidebar-content {
        background-color: var(--card-color);
        padding: 1rem;
        border-radius: 10px;
        border-left: 4px solid var(--accent-color);
    }
    
    .stat-card {
        background: linear-gradient(135deg, var(--card-color), #f0f4f8);
        padding: 1rem;
        border-radius: 10px;
        border: 1px solid #e0e0e0;
        margin: 0.5rem 0;
    }
    
    .stButton button {
        background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));
        color: white;
        border: none;
        border-radius: 8px;
        padding: 0.5rem 1rem;
        font-weight: 600;
    }
    
    .stButton button:hover {
        background: linear-gradient(135deg, var(--secondary-color), var(--primary-color));
        color: white;
    }
    
    .footer {
        text-align: center;
        padding: 1rem;
        color: var(--text-color);
        font-size: 0.9rem;
    }
    </style>
    """, unsafe_allow_html=True)

# ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ò‡∏µ‡∏°
setup_custom_theme()

# üîë ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ API KEY
genai.configure(api_key="AIzaSyD-Ga-fru_mbx74ObfjxRuQsK-n3Zd3sDQ")

generation_config = {
    "temperature": 0.1,
    "top_p": 0.95,
    "top_k": 64,
    "max_output_tokens": 1024,
    "response_mime_type": "text/plain",
}

SAFETY_SETTINGS = [
    {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
]

# ‚úÖ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô 2.0 (‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•)
def get_available_model():
    """‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô 2.0 ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ"""
    try:
        available_models = genai.list_models()
        working_models = []
        
        for model in available_models:
            if "generateContent" in model.supported_generation_methods:
                working_models.append(model.name)
        
        # ‚úÖ ‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏≠‡∏ö‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô 2.0 (‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á 2.5)
        preferred_models = [
            # Gemini 1.5 Series
            "models/gemini-1.5-flash-001",
            "models/gemini-1.5-flash",
            "models/gemini-1.5-pro-001", 
            "models/gemini-1.5-pro",
            
            # Gemini 1.0 Series
            "models/gemini-1.0-pro-001",
            "models/gemini-1.0-pro",
            "models/gemini-pro",
            
            # Fallback models
            "models/gemini-pro-vision"
        ]
        
        # ‚úÖ ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ "2.5" ‡πÉ‡∏ô‡∏ä‡∏∑‡πà‡∏≠
        filtered_models = [model for model in preferred_models if "2.5" not in model]
        
        # ‚úÖ ‡∏´‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ
        for model_name in filtered_models:
            if model_name in working_models:
                return model_name
        
        # ‚úÖ ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡∏°‡∏µ 2.5
        safe_models = [model for model in working_models if "2.5" not in model]
        if safe_models:
            return safe_models[0]
        else:
            return working_models[0] if working_models else None
        
    except Exception as e:
        # Fallback to stable model
        return "models/gemini-1.0-pro"

# ‚úÖ ‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ
chosen_model = get_available_model()

if not chosen_model:
    st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ")
    st.stop()

# ‚úÖ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏•‡πâ‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥
def clear_history():
    st.session_state["messages"] = [
        {"role": "model", "content": "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡πà‡∏∞ ‡∏î‡∏¥‡∏â‡∏±‡∏ô‡∏Ñ‡∏∑‡∏≠‡∏Ñ‡∏£‡∏π‡∏ú‡∏π‡πâ‡∏™‡∏≠‡∏ô‡∏ß‡∏¥‡∏ä‡∏≤ Instructional Science and Classroom Management ‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏™‡∏ô‡πÉ‡∏à‡∏≠‡∏¢‡∏≤‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÉ‡∏î‡∏Ñ‡∏∞"}
    ]
    if "chat_history" in st.session_state:
        st.session_state["chat_history"] = []
    st.rerun()

# ‚úÖ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£
@st.cache_data(ttl=3600)
def load_document(file_path):
    """‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ docx"""
    try:
        doc = Document(file_path)
        file_content = ""
        for para in doc.paragraphs:
            if para.text.strip():
                file_content += para.text + "\n"
        
        paragraphs = [p.strip() for p in file_content.split('\n') if p.strip() and len(p.strip()) > 10]
        return file_content, paragraphs
    except Exception as e:
        return "", []

# ‚úÖ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á
def find_relevant_content(question, paragraphs, top_n=3):
    """‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°"""
    if not paragraphs or len(paragraphs) <= top_n:
        return "\n".join(paragraphs) if paragraphs else ""
    
    try:
        question_lower = question.lower()
        relevant_paragraphs = []
        
        keyword_groups = {
            'active_learning': ['active learning', '‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡πÄ‡∏ä‡∏¥‡∏á‡∏£‡∏∏‡∏Å', '‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡πÄ‡∏ä‡∏¥‡∏á‡∏£‡∏∏‡∏Å'],
            'learning_styles': ['learning styles', '‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ', 'visual', 'auditory', 'kinesthetic'],
            'classroom_management': ['classroom management', '‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ä‡∏±‡πâ‡∏ô‡πÄ‡∏£‡∏µ‡∏¢‡∏ô'],
            'instructional_science': ['instructional science', '‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏≠‡∏ô'],
            'teaching_methods': ['‡∏Å‡∏≤‡∏£‡∏™‡∏≠‡∏ô', '‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏Å‡∏≤‡∏£‡∏™‡∏≠‡∏ô', '‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏™‡∏≠‡∏ô']
        }
        
        paragraph_scores = []
        for i, paragraph in enumerate(paragraphs):
            paragraph_lower = paragraph.lower()
            score = 0
            
            question_words = [word for word in question_lower.split() if len(word) > 2]
            for word in question_words:
                if word in paragraph_lower:
                    score += 2
            
            for group_keywords in keyword_groups.values():
                for keyword in group_keywords:
                    if keyword in paragraph_lower:
                        score += 3
                        break
            
            if score > 0:
                paragraph_scores.append((score, i, paragraph))
        
        paragraph_scores.sort(reverse=True)
        top_paragraphs = [item[2] for item in paragraph_scores[:top_n]]
        
        if top_paragraphs:
            return "\n".join(top_paragraphs)
        else:
            long_paragraphs = [p for p in paragraphs if len(p) > 50]
            return "\n".join(long_paragraphs[:top_n]) if long_paragraphs else "\n".join(paragraphs[:top_n])
            
    except Exception as e:
        return "\n".join(paragraphs[:top_n]) if paragraphs else ""

# ‚úÖ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö
def generate_response(prompt, file_content, paragraphs):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ Gemini"""
    
    if prompt.lower().strip() in ['clear', '‡∏•‡πâ‡∏≤‡∏á', 'reset', '‡πÉ‡∏´‡∏°‡πà']:
        clear_history()
        return "‡∏•‡πâ‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πà‡∏∞ ‚úÖ"
    
    relevant_content = find_relevant_content(prompt, paragraphs)
    
    context_prompt = f"""
    ‡∏ö‡∏ó‡∏ö‡∏≤‡∏ó: ‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏≠‡∏≤‡∏à‡∏≤‡∏£‡∏¢‡πå‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô Instructional Science ‡πÅ‡∏•‡∏∞ Classroom Management

    ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô:
    {relevant_content}

    ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ: {prompt}

    ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö:
    1. ‡∏ï‡∏≠‡∏ö‡πÇ‡∏î‡∏¢‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å
    2. ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢
    3. ‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡πÅ‡∏•‡∏∞‡∏ô‡∏≥‡πÑ‡∏õ‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡πÑ‡∏î‡πâ
    4. ‡∏´‡∏≤‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏Å‡∏≤‡∏£‡∏™‡∏≠‡∏ô ‡πÉ‡∏´‡πâ‡∏¢‡∏Å‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö

    ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏Ñ‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≤‡∏á‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£
    """

    try:
        model = genai.GenerativeModel(
            model_name=chosen_model,
            generation_config=generation_config,
            safety_settings=SAFETY_SETTINGS,
        )
        
        response = model.generate_content(context_prompt)
        
        if response and response.text:
            reply_text = response.text.strip()
            if len(reply_text) < 10:
                reply_text = "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ô‡∏µ‡πâ ‡πÇ‡∏õ‡∏£‡∏î‡∏•‡∏≠‡∏á‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏≠‡∏∑‡πà‡∏ô‡∏Ñ‡πà‡∏∞"
        else:
            reply_text = "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ"
            
    except Exception as e:
        error_msg = str(e)
        if "429" in error_msg or "quota" in error_msg.lower():
            reply_text = "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡πÇ‡∏Ñ‡∏ß‡∏ï‡∏≤‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏´‡∏°‡∏î‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß ‡πÇ‡∏õ‡∏£‡∏î‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏ô 1-2 ‡∏ô‡∏≤‡∏ó‡∏µ‡∏Ñ‡πà‡∏∞"
        elif "404" in error_msg:
            reply_text = "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ ‡πÇ‡∏õ‡∏£‡∏î‡∏£‡∏µ‡πÄ‡∏ü‡∏£‡∏ä‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö"
        else:
            reply_text = "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•"

    return reply_text

# ‚úÖ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤
def log_interaction(question, answer):
    """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤"""
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    if "chat_history" not in st.session_state:
        st.session_state["chat_history"] = []
    
    st.session_state["chat_history"].append({
        "timestamp": timestamp,
        "question": question,
        "answer": answer[:500]
    })

# ‚úÖ ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Streamlit UI
st.markdown('<div class="main-header"><h1>üë©‚Äçüè´ ‡∏ß‡∏¥‡∏ä‡∏≤ Instructional Science & Classroom Management</h1><p>‡πÅ‡∏ä‡∏ó‡∏ö‡∏≠‡∏ó‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏≠‡∏ô</p></div>', unsafe_allow_html=True)

# ‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£
file_path = r"dataset3.docx"
file_content, paragraphs = load_document(file_path)

# ‚úÖ ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ messages ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        {
            "role": "model",
            "content": "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡πà‡∏∞! ‡∏î‡∏¥‡∏â‡∏±‡∏ô‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏≠‡∏≤‡∏à‡∏≤‡∏£‡∏¢‡πå‡∏î‡πâ‡∏≤‡∏ô Instructional Science ‡πÅ‡∏•‡∏∞ Classroom Management ‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÉ‡∏´‡πâ‡∏î‡∏¥‡∏â‡∏±‡∏ô‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏≠‡∏ô‡πÑ‡∏´‡∏°‡∏Ñ‡∏∞?"
        }
    ]

# ‚úÖ Sidebar - ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏£‡∏∞‡∏ö‡∏ö
with st.sidebar:
    st.markdown('<div class="sidebar-content">', unsafe_allow_html=True)
    
    st.markdown("### üéõÔ∏è ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏£‡∏∞‡∏ö‡∏ö")
    
    col1, col2 = st.columns(2)
    with col1:
        if st.button("üßπ ‡∏•‡πâ‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥", use_container_width=True):
            clear_history()
    with col2:
        if st.button("üîÑ ‡∏£‡∏µ‡πÄ‡∏ü‡∏£‡∏ä", use_container_width=True):
            st.rerun()
    
    st.markdown("---")
    
    # ‚úÖ ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πå‡∏î‡∏™‡∏ß‡∏¢‡∏á‡∏≤‡∏°
    st.markdown("### üìä ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏£‡∏∞‡∏ö‡∏ö")
    
    st.markdown('<div class="stat-card">', unsafe_allow_html=True)
    if file_content:
        st.metric("üìÑ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤", len(paragraphs))
        st.metric("üî§ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£", f"{len(file_content):,}")
    else:
        st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£")
    st.markdown('</div>', unsafe_allow_html=True)
    
    st.markdown('<div class="stat-card">', unsafe_allow_html=True)
    if "chat_history" in st.session_state:
        st.metric("üí¨ ‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤", len(st.session_state["chat_history"]))
    else:
        st.metric("üí¨ ‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤", 0)
    st.markdown('</div>', unsafe_allow_html=True)
    
    # ‚úÖ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏•
    st.markdown("### ü§ñ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏•")
    st.markdown('<div class="stat-card">', unsafe_allow_html=True)
    st.success(f"**‡πÇ‡∏°‡πÄ‡∏î‡∏•:** {chosen_model.split('/')[-1]}")
    
    model_type = "üöÄ Flash" if "flash" in chosen_model.lower() else "üíé Pro"
    st.info(f"**‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó:** {model_type}")
    
    st.success("**‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞:** üü¢ ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ")
    st.markdown('</div>', unsafe_allow_html=True)
    
    # ‚úÖ ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
    st.markdown("### üí° ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥")
    st.markdown("""
    - üéØ **Active Learning** - ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡πÄ‡∏ä‡∏¥‡∏á‡∏£‡∏∏‡∏Å
    - üé® **Learning Styles** - ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ  
    - üè´ **Classroom Management** - ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ä‡∏±‡πâ‡∏ô‡πÄ‡∏£‡∏µ‡∏¢‡∏ô
    - üë©‚Äçüè´ **Teaching Methods** - ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏™‡∏≠‡∏ô
    """)
    
    st.markdown('</div>', unsafe_allow_html=True)

# ‚úÖ ‡πÅ‡∏™‡∏î‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÅ‡∏ö‡∏ö‡∏™‡∏ß‡∏¢‡∏á‡∏≤‡∏°
for msg in st.session_state["messages"]:
    if msg["role"] == "user":
        with st.chat_message("user", avatar="üë§"):
            st.markdown(f'<div class="chat-user">{msg["content"]}</div>', unsafe_allow_html=True)
    else:
        with st.chat_message("assistant", avatar="üë©‚Äçüè´"):
            st.markdown(f'<div class="chat-assistant">{msg["content"]}</div>', unsafe_allow_html=True)

# ‚úÖ ‡∏™‡πà‡∏ß‡∏ô‡∏´‡∏•‡∏±‡∏Å chatbot
st.markdown("---")
if prompt := st.chat_input("üí¨ ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏≠‡∏ô..."):
    if prompt.strip():
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
        st.session_state["messages"].append({"role": "user", "content": prompt})
        with st.chat_message("user", avatar="üë§"):
            st.markdown(f'<div class="chat-user">{prompt}</div>', unsafe_allow_html=True)
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö
        with st.spinner("üîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö..."):
            response = generate_response(prompt, file_content, paragraphs)
            
        st.session_state["messages"].append({"role": "model", "content": response})
        with st.chat_message("assistant", avatar="üë©‚Äçüè´"):
            st.markdown(f'<div class="chat-assistant">{response}</div>', unsafe_allow_html=True)
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥
        log_interaction(prompt, response)

# ‚úÖ Footer
st.markdown("---")
st.markdown("""
<div class="footer">
    <p>ü§ñ ‡πÅ‡∏ä‡∏ó‡∏ö‡∏≠‡∏ó‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡∏ä‡∏≤ Instructional Science and Classroom Management</p>
    <p>Powered by Google Gemini AI | Theme: Blue-Green-White</p>
</div>
""", unsafe_allow_html=True)